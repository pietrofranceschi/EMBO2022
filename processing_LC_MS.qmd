---
title: "Processing LC-MS Metabolomics Data with `xcms`"
author: "Pietro Franceschi"
format: 
  revealjs: 
    slide-number: true
    chalkboard: 
      buttons: true
    footer: pietro.franceschi@fmach.it
---

## What is `xcms`



## Outline {.smaller background-image="images/numbers.jpg"}

* Data analysis, organization and data matrices
* Some thoughts on validation
* Preprocessing and analytical variability
* MS for Dummies
* LC-MS data handling
* Demo & DIY
* Peak Picking in `xcms`
* Demo & DIY
* Retention time correction and features definition
* Demo & DIY
* Dealing with Fragmentation esperiments
* Demo & DIY

## The data matrix

![](images/Matrix.svg){fig-align="center" width=50%}



## The role of Data Analysis


```{r}
library(tidyverse)
library(patchwork)
library(xcms)
library(plotly)
```


Statistics, Bionformatics, Machine Learning, Chemometrics, ..., provide the tools to:

* make science shared and reproducible ... ;-)
* process and organize **big data** into the matrix
* identify the presence of **organization** in the data matrix
* assess the confidence that our result is true "at the population level"


## Examples of Organization


```{r}

a <- tibble(class = rep(c("A","B"), each = 100),
       intensity = c(rnorm(100,10), rnorm(100,11))) %>% 
  ggplot() + 
  geom_jitter(aes(x = class, y = intensity, col = class), width = 0.1) + 
  theme_bw() + 
  theme(aspect.ratio = 1)


b <- tibble(met_a = runif(20,0,10)) %>%
  mutate(noise = rnorm(20)) %>% 
  mutate(met_b = met_a*2 + noise) %>% 
  ggplot() + 
  geom_point(aes(x = met_a, y = met_b), col = "steelblue", size = 2) + 
  theme_bw() + 
  theme(aspect.ratio = 1)


b|a

```

## Fat Data Matrices 

The typical metabolomics data matrix looks like this:

```{r, fig.align = 'center'}
library(reshape2)
random_data <- matrix(rnorm(2000*20), nrow = 20) 

random_data [,1:200] %>% 
  melt() %>%
  ggplot(aes(x = Var2, y = Var1)) + 
  geom_raster(aes(fill=value)) + 
  scale_fill_viridis_c() +
  coord_fixed()+
  theme_void() + theme(legend.position = "none", )
```

Let's take 20 samples and 2000 variables ... and fill the matrix of random numbers

## Correlation coefficients

```{r}
#| fig-height: 6
#| fig-align: center

mycor <- cor(random_data)


hist(mycor[upper.tri(mycor)], col = "steelblue", 
     main = "Pearson Correlation", xlab = "Correlation",
     border = "white")

```

Range of correlations: `r round(range(mycor[upper.tri(mycor)]),2)`


We have relatively large values. Why? 

## False Positives {background-image="images/brain_bg.svg"}

::: {layout="[[1,-0.3]]" layout-valign="center"}

* Organization can show up only by chance
* These results are *true*, but the hold only for the data we are analyzing now
* Organization is not necessarily science
* Variability causes this
* We need to *validate* our outcomes

:::

## On Validation

* **Statistical Validation**: get brand new samples and see if what we get is still there
* **Domain Validation**: is what I'm getting in keeping with the domain specific body of knowledge? Could I design an experiment to check my hypothesis?


## By the way ...

* What are the variables measured in a *targeted metabolomics assay?*
* What are the variables measured in an *untargeted LC-MS metabolomics experiment?*
* What are the variables measured in an *untargeted NMR metabolomics experiment?*


## LC-MS For Dummies

![](images/LCMS.jpg){fig-align="center"}


## Preprocessing

::: incremental
* I call **preprocessing** all the data carpentry steps I do to go from the raw experimental data to the data matrix
* The aim of this process is to compensate for *analytical variability* being able to reliably build a data matrix
* *QC samples* play a big role on that because they are sensitive only to analytical variability
:::

## Uses of QCs {background-image="images/brain_bg.svg"}

::: {layout="[[1,-0.3]]" layout-valign="center"}

*QCs should be representative of the chemical complexity of your samples*

* correct for retention time shifts
* identify <span style="color: red">reliable</span> variables: 
    * variance in QC should be smaller than in samples
    * they should decrease during dilution
    * ...
* help in correcting for bath effects ...

:::


## Analytical Variability in LC-MS: mass

![](images/mass_drift.png){fig-align="center"}


## Analytical Variability in LC-MS: retention time

```{r}

fnames <- list.files("data/apples/","CDF", full.names = TRUE)

apples <- readMSData(fnames, mode = "onDisk") 

```

```{r}
bpi <- apples %>% filterRt(c(250,410)) %>% chromatogram(aggregationFun = "max")
```

```{r}
#| fig-height: 6
#| fig-align: center

plot(bpi, col = "steelblue", main = "BPI")
```



## Analytical Variability in LC-MS: intensity





## LC-MS produces 3D data (rt,mz,I)
![](images/LCMS_data.png){fig-align="center"}

#### Things too look at
* Extracted Ion Trace/Current (EIT/EIC)
* Mass Spectra


## Extracted ion traces

```{r}
#| fig-height: 6
#| fig-align: center

register(SerialParam())
proc_trace <- chromatogram(apples %>% filterRt(c(100,500)), mz = 577.13 + c(-1,1)*0.01)
plot(proc_trace, col = "coral")
```


## Mass Spectra

```{r}

#| fig-height: 6
#| fig-align: center


ms <- apples[[1000]]

tibble(mz =  mz(ms), i = intensity(ms)) %>% 
  ggplot() + 
  geom_segment(aes(x = mz, xend = mz, y = 0, yend = i)) + 
  theme_bw()



```



## Back to Raw data

Always check your results on the raw data

* Problems in preprocessing
* bad peaks
* biomarkers
* results hidden in noise


##

::: {layout="[[-1], [1], [-1]]"}
![](images/RStudio.png){fig-align="center"}
:::

# Peak Picking

## Peaks and metabolites: facts {background-image="images/brain_bg.svg"}

::: {layout="[[1,-0.3]]" layout-valign="center"}
* A metabolite produce peaks in the extracted ion traces of its associated ions
* Different peaks in the same ion chromatograms are associated to different metabolites
* Peaks are not metabolites
* The same peak can slightly move across the injections

### We need methods to automatically find peaks

:::

## MatchedFilter

![](images/matchedFilter.png){width=60% fig-align="center"}


::: footer
Anal Chem 2006 1;78(3):779-87. doi: 10.1021/ac051437y.
:::

## Cent Wave

![](images/cent_wave.png){width=50% fig-align="center"}


::: footer
BMC Bioinformatics 9, 504 (2008). https://doi.org/10.1186/1471-2105-9-504
:::

## Things to always consider {background-image="images/eye_bg.svg"}


::: {layout="[[1,-0.3]]" layout-valign="center"}
::: incremental
* Real peaks can be really badly shaped
* You are better than an algorithm ... well AI should do well
* Every algorithm has parameters to tune!
* Look to the data!
* Know how the instrument works
:::
:::

##

::: {layout="[[-1], [1], [-1]]"}
![](images/RStudio.png){fig-align="center"}
:::




